{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries and Download the Dataset","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom tensorflow.keras import layers\nimport tensorflow_datasets as tfds\nfrom tensorflow import keras\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nds, info = tfds.load('tf_flowers',\n              # take 80% for training, 10% for validation, and 10% for testing\n              split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:100%]\"],\n              as_supervised=True,\n              with_info=True)\ntrain_set, valid_set, test_set = ds","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-11T15:33:14.651357Z","iopub.execute_input":"2021-11-11T15:33:14.651594Z","iopub.status.idle":"2021-11-11T15:33:25.401727Z","shell.execute_reply.started":"2021-11-11T15:33:14.651526Z","shell.execute_reply":"2021-11-11T15:33:25.400982Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"info.splits['train'].num_examples","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:33:25.403388Z","iopub.execute_input":"2021-11-11T15:33:25.403817Z","iopub.status.idle":"2021-11-11T15:33:25.412354Z","shell.execute_reply.started":"2021-11-11T15:33:25.403767Z","shell.execute_reply":"2021-11-11T15:33:25.411578Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class_names = info.features['label'].names\nclass_names","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:33:25.413843Z","iopub.execute_input":"2021-11-11T15:33:25.414497Z","iopub.status.idle":"2021-11-11T15:33:25.421001Z","shell.execute_reply.started":"2021-11-11T15:33:25.414454Z","shell.execute_reply":"2021-11-11T15:33:25.420302Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Visualize the images","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\ni = 0\nfor image, label in train_set.take(9):\n    plt.subplot(3, 3, i + 1)\n    image = tf.image.resize(image, (224, 224))\n    plt.imshow(image.numpy().astype(\"uint8\"))\n    plt.title(class_names[label])\n    plt.axis(\"off\")\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:33:25.423189Z","iopub.execute_input":"2021-11-11T15:33:25.423640Z","iopub.status.idle":"2021-11-11T15:33:26.266624Z","shell.execute_reply.started":"2021-11-11T15:33:25.423604Z","shell.execute_reply":"2021-11-11T15:33:26.266006Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Prepare the Dataset","metadata":{}},{"cell_type":"code","source":"# declare some variables\nbatch_size = 32\nimg_height = 224\nimg_width = 224\nAUTOTUNE = tf.data.AUTOTUNE\n\n# We will use this layer to standardize the pixel values\nrescaling_layer = layers.Rescaling(1./255)\n\n\ndef create_dataset(ds, shuffle=False):\n    if shuffle:\n        ds = ds.shuffle(1000)\n    # resize the images\n    ds = ds.map(\n        lambda x, y: (tf.image.resize(x, (img_height, img_width)), y)\n    )\n    # standardize the pixel values to the [0 ,1] range\n    ds = ds.map(lambda x, y: (rescaling_layer(x), y))\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(AUTOTUNE)\n    return ds\n\ntrain_set = create_dataset(train_set, shuffle=True)\nvalid_set = create_dataset(valid_set)\ntest_set = create_dataset(test_set)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:33:26.267538Z","iopub.execute_input":"2021-11-11T15:33:26.267746Z","iopub.status.idle":"2021-11-11T15:33:26.364363Z","shell.execute_reply.started":"2021-11-11T15:33:26.267718Z","shell.execute_reply":"2021-11-11T15:33:26.363731Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Extract the Features","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\n\nimg_size = (img_height, img_width, 3)\nconv_base = VGG16(input_shape=(img_size),\n                   include_top=False,\n                   weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:33:26.365657Z","iopub.execute_input":"2021-11-11T15:33:26.365906Z","iopub.status.idle":"2021-11-11T15:33:26.954819Z","shell.execute_reply.started":"2021-11-11T15:33:26.365873Z","shell.execute_reply":"2021-11-11T15:33:26.954067Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"conv_base.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:33:26.956200Z","iopub.execute_input":"2021-11-11T15:33:26.956446Z","iopub.status.idle":"2021-11-11T15:33:26.972981Z","shell.execute_reply.started":"2021-11-11T15:33:26.956412Z","shell.execute_reply":"2021-11-11T15:33:26.972212Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def extract_features(dataset):\n    # here we will store the extracted features and their labels\n    features = []\n    labels = []\n\n    total_batchs = tf.data.experimental.cardinality(dataset)\n    current_batch = 1\n\n    # loop over the dataset to get batches of images and their labels\n    for images_batch, labels_batch in dataset:\n        print(\"[INFO] processing batch {}/{}\".format(current_batch, total_batchs))\n        # extract the features using the predict method\n        # the shape will be (32, 7, 7, 512)\n        features_batch = conv_base.predict(images_batch)\n\n        # store the current batch of features and labels in a list\n        features.append(features_batch)\n        labels.append(labels_batch)\n        current_batch += 1\n\n    features = np.vstack(features) # shape: (2936, 7, 7, 512)\n    labels = np.hstack(labels)     # shape: (2936,)\n    # flatten the features\n    features = features.reshape(features.shape[0], 7 * 7 * 512)\n\n    return features, labels\n\n\nprint('[INFO] extracting features from training dataset ...')\ntrain_features, train_labels = extract_features(train_set)\nprint('[INFO] extracting features from validation dataset ...')\nvalidation_features, validation_labels = extract_features(valid_set)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:33:26.975530Z","iopub.execute_input":"2021-11-11T15:33:26.975712Z","iopub.status.idle":"2021-11-11T15:34:00.176433Z","shell.execute_reply.started":"2021-11-11T15:33:26.975690Z","shell.execute_reply":"2021-11-11T15:34:00.175589Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Train a New FC Classifier on the Extracted Features","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    layers.Dense(128, activation='relu', input_dim=7 * 7 * 512),\n    layers.Dense(5, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(train_features, train_labels,\n                    epochs=10,\n                    validation_data=(validation_features, validation_labels))","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:34:00.177830Z","iopub.execute_input":"2021-11-11T15:34:00.178109Z","iopub.status.idle":"2021-11-11T15:34:05.078648Z","shell.execute_reply.started":"2021-11-11T15:34:00.178071Z","shell.execute_reply":"2021-11-11T15:34:05.077841Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Visualize the Results","metadata":{}},{"cell_type":"code","source":"def plot_learning_curves():\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    plt.figure(figsize=(10, 8))\n    plt.subplot(2, 1, 1)\n    plt.plot(acc, label=\"Training Accuracy\")\n    plt.plot(val_acc, label=\"Validation Accuracy\")\n    plt.legend()\n    plt.grid(True)\n\n    plt.subplot(2, 1, 2)\n    plt.plot(loss, label=\"Training Loss\")\n    plt.plot(val_loss, label=\"Validation Loss\")\n    plt.legend()\n    plt.grid(True)\n\n    plt.show()\n\nplot_learning_curves()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:34:05.081681Z","iopub.execute_input":"2021-11-11T15:34:05.082143Z","iopub.status.idle":"2021-11-11T15:34:05.443547Z","shell.execute_reply.started":"2021-11-11T15:34:05.082104Z","shell.execute_reply":"2021-11-11T15:34:05.442685Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning with Data Augmentation","metadata":{}},{"cell_type":"code","source":"data_augmentation = Sequential([\n    layers.RandomFlip(\"horizontal\", input_shape=(img_size)),\n    layers.RandomRotation(0.2),\n    layers.RandomZoom(0.2),\n  ])\n\nbase_model = tf.keras.applications.VGG16(\n        input_shape=img_size,\n        include_top=False,\n        weights=\"imagenet\",\n)\n# freeze all layers of the base model\nbase_model.trainable = False\n\nmodel = Sequential([\n    data_augmentation,\n    base_model,\n    layers.Dropout(0.5),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(5)\n])\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nepochs=10\nhistory = model.fit(\n  train_set,\n  validation_data=valid_set,\n  epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:34:05.445272Z","iopub.execute_input":"2021-11-11T15:34:05.445561Z","iopub.status.idle":"2021-11-11T15:35:28.429300Z","shell.execute_reply.started":"2021-11-11T15:34:05.445521Z","shell.execute_reply":"2021-11-11T15:35:28.428527Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"plot_learning_curves()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:35:28.432270Z","iopub.execute_input":"2021-11-11T15:35:28.432469Z","iopub.status.idle":"2021-11-11T15:35:28.774464Z","shell.execute_reply.started":"2021-11-11T15:35:28.432445Z","shell.execute_reply":"2021-11-11T15:35:28.773812Z"},"trusted":true},"execution_count":12,"outputs":[]}]}